{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from transformers import pipeline\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import mysql.connector\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Suppress the specific FutureWarning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_22348\\1440592860.py:6: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"transformers.tokenization_utils_base\")\n",
    "warnings.filterwarnings('ignore',message='The name tf.losses.sparse_softmax_cross_entropy is deprecated')\n",
    "warnings.filterwarnings('ignore',message='The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **All Product URL :-**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Product_URL_01 = \"https://www.flipkart.com/fitoda-fashion-men-graphic-print-casual-multicolor-shirt/p/itmb1e9ad9ec3320?pid=SHTGKW43PPG4MYEM&lid=LSTSHTGKW43PPG4MYEMKKK7UK&marketplace=FLIPKART&fm=productRecommendation%2Fsimilar&iid=R%3As%3Bp%3ASHTGFQVTBGSDQHNY%3Bl%3ALSTSHTGFQVTBGSDQHNYKBCECM%3Bpt%3App%3Buid%3A61e32bf4-7bcb-11ef-b7fb-975dfaf6ad6e%3B.SHTGKW43PPG4MYEM&ppt=pp&ppn=pp&ssid=lntb3u2ebk0000001727329869450&otracker=pp_reco_Similar%2BProducts_1_34.productCard.PMU_HORIZONTAL_fitoda%2Bfashion%2BMen%2BGraphic%2BPrint%2BCasual%2BMulticolor%2BShirt_SHTGKW43PPG4MYEM_productRecommendation%2Fsimilar_0&otracker1=pp_reco_PINNED_productRecommendation%2Fsimilar_Similar%2BProducts_GRID_productCard_cc_1_NA_view-all&cid=SHTGKW43PPG4MYEM\"\n",
    "product_URL_02 = \"https://www.flipkart.com/marmic-fab-men-printed-casual-white-black-shirt/p/itmd14749f2319a7?pid=SHTGJXUJWGNH7KZ7&lid=LSTSHTGJXUJWGNH7KZ7OPLKGR&marketplace=FLIPKART&sattr[]=color&st=color\"\n",
    "product_URL_03 = \"https://www.flipkart.com/combraided-men-solid-casual-light-blue-shirt/p/itm7331f7b6e2618?pid=SHTG6AGZUNZRJY2H&lid=LSTSHTG6AGZUNZRJY2HS3L2RZ&marketplace=FLIPKART&store=clo%2Fash&srno=b_1_2&otracker=browse&otracker1=hp_rich_navigation_PINNED_neo%2Fmerchandising_NA_NAV_EXPANDABLE_navigationCard_cc_1_L2_view-all&fm=organic&iid=en_sZ5f25YUi1yLU5aq0hfKLL5JeCOq2ITn5kSMbYh7vpQ_ETLH_df6VOOs-oo7t4aI1L5k2lqY-9gm-RNnBLn7vQ%3D%3D&ppt=browse&ppn=browse&ssid=olt3rp9t3k0000001727359632948\"\n",
    "product_URL_04 = \"https://www.flipkart.com/y-company-casual-self-design-women-white-top/p/itmc45623bf375df?pid=TOPGZKQ2HHEXGYAC&lid=LSTTOPGZKQ2HHEXGYACHURA7W&marketplace=FLIPKART&q=beach+wear+tops+for+women&store=clo%2Fash%2Fohw%2F36j&spotlightTagId=BestsellerId_clo%2Fash%2Fohw%2F36j&srno=s_1_1&otracker=AS_Query_OrganicAutoSuggest_7_4_na_na_ps&otracker1=AS_Query_OrganicAutoSuggest_7_4_na_na_ps&fm=search-autosuggest&iid=b0788323-36ac-41bc-b016-119708205e33.TOPGZKQ2HHEXGYAC.SEARCH&ppt=sp&ppn=sp&ssid=fxybozal680000001727363123575&qH=a5683c78cacfd0b6\"\n",
    "product_URL_05 = \"\"\n",
    "product_URL_06 = \"\"\n",
    "product_URL_07 = \"\"\n",
    "product_URL_08 = \"\"\n",
    "product_URL_09 = \"\"\n",
    "product_URL_10 = \"\"\n",
    "product_URL_11 = \"\"\n",
    "product_URL_12 = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Product Details** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run the browser in headless mode\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(product_URL_02)\n",
    "time.sleep(0)  # Let the page load\n",
    "\n",
    "# Scroll down to load more Details (adjust the number of scrolls as needed)\n",
    "scrolls = 3\n",
    "for _ in range(scrolls):\n",
    "    driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.END)\n",
    "    time.sleep(0)\n",
    "# Get the page source after scrolling\n",
    "Product_Page = driver.page_source\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "# Now you can use BeautifulSoup to parse the loaded content\n",
    "HTML = bs(Product_Page, 'html.parser')\n",
    "\n",
    "Product_Name = HTML.find(\"span\",{\"class\":\"VU-ZEz\"}).text.replace('\\xa0', ' ').strip()\n",
    "Product_Image = HTML.find(\"img\",{\"class\":\"_53J4C- utBuJY\"}).get('src')\n",
    "Hover_Image = HTML.find(\"div\", {\"class\": \"Pz+aTd\"}).img.get('src')\n",
    "Original_Price = float(HTML.find('div', class_=['yRaY8j', 'A6+E6v']).get_text().strip().replace('₹', '').replace(',', '').strip())\n",
    "Discount = float(HTML.find(\"div\",{\"class\":\"UkUFwK WW8yVX dB67CR\"}).text.replace(\"% off\",\"\"))\n",
    "Special_Price = float(HTML.find(\"div\",{\"class\":\"Nx9bqj CxhGGd\"}).text.replace('₹','').replace(',',''))\n",
    "Product_Rating = float(HTML.find(\"div\",{\"class\":\"XQDdHH\"}).text)\n",
    "Total_Number_of_Ratings = int((re.findall(r'\\d{1,3}(?:,\\d{3})*', HTML.find_all(\"span\",{\"class\":\"Wphh3N\"})[0].span.text))[0].replace(',', ''))\n",
    "Total_Number_of_Reviews = int((re.findall(r'\\d{1,3}(?:,\\d{3})*', HTML.find_all(\"span\",{\"class\":\"Wphh3N\"})[0].span.text))[1].replace(',', ''))\n",
    "Delivery_Date = HTML.find('span', class_='Y8v7Fl').text.split(\",\")[0]\n",
    "Seller_Name = HTML.find(\"div\",{\"class\":\"yeLeBC\"}).span.span.text\n",
    "Seller_Rating = float(HTML.find(\"div\",{\"class\":\"yeLeBC\"}).div.text)\n",
    "Link = HTML.find(\"div\",{\"class\":\"col pPAw9M iIbIvC\"}).find_all('a')[-1].get('href')\n",
    "\n",
    "# Return the product details in a dictionary\n",
    "Product_Detail = {\n",
    "    \"Product URL\": Product_URL_01,\n",
    "    \"Product Name\": Product_Name,\n",
    "    \"Product Image\": Product_Image,\n",
    "    \"Hover Image\": Hover_Image,\n",
    "    \"Original Price\": Original_Price,\n",
    "    \"Discount %\": Discount,\n",
    "    \"Special Price\": Special_Price,\n",
    "    \"Rating\": Product_Rating,\n",
    "    \"Total Number of Ratings\": Total_Number_of_Ratings,\n",
    "    \"Total Number of Reviews\": Total_Number_of_Reviews,\n",
    "    \"Delivery Date\": Delivery_Date,\n",
    "    \"Seller Name\": Seller_Name,\n",
    "    \"Seller Rating\": Seller_Rating,\n",
    "    \"Link\": Link\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reviews_Page_URL = [f\"https://www.flipkart.com{Product_Detail['Link']}&page={i}\" for i in range(1, 11)]\n",
    "Buyer_Name = []\n",
    "Rating = []\n",
    "Comment = []\n",
    "\n",
    "for i in Reviews_Page_URL:\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")  # Run the browser in headless mode\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(i)\n",
    "    time.sleep(0)  # Let the page load\n",
    "    scrolls = 3\n",
    "    for _ in range(scrolls):\n",
    "        driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.END)\n",
    "        time.sleep(0)\n",
    "    Page = driver.page_source\n",
    "    driver.quit()\n",
    "    Reviews_HTML = bs(Page, 'html.parser')\n",
    "\n",
    "    for i in Reviews_HTML.find_all(\"p\",{\"class\":\"_2NsDsF AwS1CA MDcJkH\"}):\n",
    "        Buyer_Name.append(i.text)\n",
    "\n",
    "    for i in Reviews_HTML.find_all(\"div\", {\"class\": \"cPHDOP col-12-12\"})[2:-1]:\n",
    "        first_class = i.find(\"div\", {\"class\": \"XQDdHH Ga3i8K _9lBNRY\"})\n",
    "        second_class = i.find(\"div\", {\"class\": \"XQDdHH Czs3gR Ga3i8K _9lBNRY\"})\n",
    "        third_class = i.find(\"div\", {\"class\": \"XQDdHH Js30Fc Ga3i8K _9lBNRY\"})\n",
    "        if first_class:\n",
    "            Rating.append(int(first_class.text))\n",
    "        elif second_class:\n",
    "            Rating.append(int(second_class.text))\n",
    "        elif third_class:\n",
    "            Rating.append(int(third_class.text))\n",
    "            \n",
    "    for i in Reviews_HTML.find_all(\"div\",{\"class\":\"_11pzQk\"}):\n",
    "        Comment.append(i.text)\n",
    "\n",
    "dict = {\n",
    "    \"Name\" : Buyer_Name,\n",
    "    \"Rating\" : Rating,\n",
    "    \"Comment\" : Comment\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment = sia.polarity_scores(text)\n",
    "    if sentiment['compound'] >= 0.05:\n",
    "        return 'positive'\n",
    "    elif sentiment['compound'] <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentiment(text):\n",
    "    # Load sentiment analysis pipeline\n",
    "    sentiment_pipeline = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "    result = sentiment_pipeline(text)\n",
    "    return result[0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process():\n",
    "    df['cleaned_review'] = df['Comment'].apply(clean_text)\n",
    "    df['tokens'] = df['cleaned_review'].apply(word_tokenize)\n",
    "    df['sentiment'] = df['cleaned_review'].apply(get_sentiment)\n",
    "    df['sentiment'] = df['Comment'].apply(classify_sentiment)\n",
    "    Positive_Review = round(((df[df['sentiment'] == 'POSITIVE'].shape[0])/100)*100)\n",
    "    Negative_Review = round(((df[df['sentiment'] == 'NEGATIVE'].shape[0])/100)*100)\n",
    "    Neutral_Review = round(((df[df['sentiment'] == 'NEUTRAL'].shape[0])/100)*100)\n",
    "    Product_Detail['Positive Reviews %'] = Positive_Review\n",
    "    Product_Detail['Negative Reviews %'] = Negative_Review\n",
    "    Product_Detail['Neutral Reviews %'] = Neutral_Review\n",
    "    return Product_Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Product_Detail = process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Establish database connection\n",
    "connection = mysql.connector.connect(\n",
    "    host=os.getenv('MYSQL_HOST'),\n",
    "    user=os.getenv('MYSQL_USER'),\n",
    "    password=os.getenv('MYSQL_PASSWORD'),\n",
    "    database=os.getenv('MYSQL_DB')\n",
    ")\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Create table if it doesn't exist\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS product_details (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        product_url TEXT,\n",
    "        product_name TEXT,\n",
    "        product_image TEXT,\n",
    "        hover_image TEXT,\n",
    "        original_price FLOAT,\n",
    "        discount FLOAT,\n",
    "        special_price FLOAT,\n",
    "        overall_rating FLOAT,\n",
    "        total_ratings INT,\n",
    "        total_reviews INT,\n",
    "        expected_delivery_date TEXT,\n",
    "        seller_name TEXT,\n",
    "        seller_rating FLOAT,\n",
    "        positive_reviews_percentage FLOAT,\n",
    "        negative_reviews_percentage FLOAT,\n",
    "        neutral_reviews_percentage FLOAT\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Ensure all values are in the correct format\n",
    "for key, value in Product_Detail.items():\n",
    "    if isinstance(value, list):  # Convert list to string\n",
    "        Product_Detail[key] = ', '.join(map(str, value))\n",
    "    elif value == '' or value is None:  # Handle empty or None values\n",
    "        Product_Detail[key] = None\n",
    "    elif key in [\"Original Price\", \"Discount %\", \"Special Price\", \"Rating\", \"Seller Rating\",\n",
    "                 \"Positive Reviews %\", \"Negative Reviews %\", \"Neutral Reviews %\"]:\n",
    "        # Convert numeric fields to float\n",
    "        Product_Detail[key] = float(value) if value not in [None, ''] else None\n",
    "    elif key in [\"Total Number of Ratings\", \"Total Number of Reviews\"]:\n",
    "        # Convert to integers\n",
    "        Product_Detail[key] = int(value) if value not in [None, ''] else None\n",
    "\n",
    "# Insert product details into the database\n",
    "insert_query = '''\n",
    "    INSERT INTO product_details (\n",
    "        product_url, product_name, product_image, hover_image, original_price, discount, special_price, overall_rating, \n",
    "        total_ratings, total_reviews, expected_delivery_date, seller_name, seller_rating, \n",
    "        positive_reviews_percentage, negative_reviews_percentage, neutral_reviews_percentage\n",
    "    ) \n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    '''\n",
    "\n",
    "# Execute the query\n",
    "cursor.execute(insert_query, (\n",
    "    Product_Detail.get(\"Product URL\"), Product_Detail.get(\"Product Name\"), Product_Detail.get(\"Product Image\"),\n",
    "    Product_Detail.get(\"Hover Image\"), Product_Detail.get(\"Original Price\"), Product_Detail.get(\"Discount %\"),\n",
    "    Product_Detail.get(\"Special Price\"), Product_Detail.get(\"Rating\"), Product_Detail.get(\"Total Number of Ratings\"),\n",
    "    Product_Detail.get(\"Total Number of Reviews\"), Product_Detail.get(\"Delivery Date\"), Product_Detail.get(\"Seller Name\"),\n",
    "    Product_Detail.get(\"Seller Rating\"), Product_Detail.get(\"Positive Reviews %\"), Product_Detail.get(\"Negative Reviews %\"),\n",
    "    Product_Detail.get(\"Neutral Reviews %\")\n",
    "))\n",
    "\n",
    "# Commit the transaction\n",
    "connection.commit()\n",
    "\n",
    "# Close the cursor and connection\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
